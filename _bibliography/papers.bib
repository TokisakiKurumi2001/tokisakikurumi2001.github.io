---
---
@article{khoi2024unibridge,
  abbr={ACL},
  title={UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for Low-Resource Languages},
  author={Le, Khoi and Pham, Trinh and Tuan, Luu Anh},
  journal={Proceedings of ACL},
  year={2024},
  selected={true},
  abstract={In this paper, we introduce UniBridge (Cross-Lingual Transfer Learning with Optimized Embeddings and Vocabulary), a comprehensive approach developed to improve the effectiveness of Cross-Lingual Transfer Learning, particularly in languages with limited resources. Our approach tackles two essential elements of a language model: the initialization of embeddings and the optimal vocabulary size. Specifically, we propose a novel embedding initialization method that leverages both lexical and semantic alignment for a language. In addition, we present a method for systematically searching for the optimal vocabulary size, ensuring a balance between model complexity and linguistic coverage. Our experiments across multilingual datasets show that our approach greatly improves the F1-Score in several languages. UniBridge is a robust and adaptable solution for cross-lingual systems in various languages, highlighting the significance of initializing embeddings and choosing the right vocabulary size in cross-lingual environments.},
  arxiv={2406.09717},
  code={https://github.com/VinAIResearch/UniBridge}
}

@article{khoi2024lampat,
  abbr={AAAI},
  title={LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using Adversarial Training},
  author={Le, Khoi and Pham, Trinh and Quan, Tho and Tuan, Luu Anh},
  journal={Proceedings of AAAI},
  year={2024},
  selected={true},
  abstract={Paraphrases are texts that convey the same meaning while using different words or sentence structures. It can be used as an automatic data augmentation tool for many Natural Language Processing tasks, especially when dealing with low-resource languages, where data shortage is a significant problem. To generate a paraphrase in multilingual settings, previous studies have leveraged the knowledge from the machine translation field, i.e., forming a paraphrase through zero-shot machine translation in the same language. Despite good performance on human evaluation, those methods still require parallel translation datasets, thus making them inapplicable to languages that do not have parallel corpora. To mitigate that problem, we proposed the first unsupervised multilingual paraphrasing model, LAMPAT ($\textbf{L}$ow-rank $\textbf{A}$daptation for $\textbf{M}$ultilingual $\textbf{P}$araphrasing using $\textbf{A}$dversarial $\textbf{T}$raining), by which monolingual dataset is sufficient enough to generate a human-like and diverse sentence. Throughout the experiments, we found out that our method not only works well for English but can generalize on unseen languages as well.},
  arxiv={2401.04348},
  code={https://github.com/VinAIResearch/LAMPAT},
}